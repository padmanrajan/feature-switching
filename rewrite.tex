\documentclass{article}
\usepackage{graphicx}
\usepackage{epsfig,epstopdf}
\usepackage{amssymb,amsmath,bm}
\usepackage{textcomp}
\usepackage{caption}
\usepackage{multirow}
\usepackage{nonfloat}
\usepackage{flushend}
\usepackage{subfigure}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{url}

\DeclareMathSizes{10}{10}{10}{10}

\title{Feature-switching paper draft today modified again from Mandi}

\begin{document}

\section{Introduction}
\label{sec:intro}
Feature extraction is a crucial step in pattern recognition systems. For
speech signals, feature extraction is a transformation from the acoustic space
to a feature space. In text-independent speaker verification, the objective is
to determine if two utterances (the enrolment utterance and the test utterance) are
both spoken by a particular speaker. We expect that, the transformation into the
feature space effectively discriminates the utterances spoken by the speaker
under consideration with those spoken by other speakers. Most speaker
verification systems, however, apply the same transformation, no matter which
speaker is being considered. In this paper, we explore a new paradigm, which
exploits the \emph{diversity of information} present in different feature spaces
for speaker verification. The underlying assumption is that different speakers
may be better discriminated by different features. Hence, performance can
be improved by selecting the `well-suited' feature transformation for
each speaker. We term this technique \emph{feature-switching}. 
%Building of such
%a system involves determining the better-suited feature for every speaker.

Traditionally, the diversity of different feature transformations have been
utilised by combining them. These include the so-called \emph{early fusion},
which is a combination at the feature level, and \emph{late fusion}, which is at
the classifier (or decision) level. Combining the information from multiple
feature transformations usually results in improved performance, though
with an increase in system complexity. Feature-switching aims to utilise
information from multiple feature representations, although in a non-traditional
manner. Early fusion systems typically work by concatenating feature vectors;
hence the resulting feature space is of higher dimensions. This in turn requires
more data to effectively train statistical models. Late fusion requires
individual systems to be developed and fused; in platforms with limited memory or
storage space, this could be undesirable. The feature-switching technique
attempts to get the benefit of multiple feature representations, at the same
time, reduce the system complexity and storage requirements.

Most feature representations transform the speech signal into its spectral
representation. The short-term Fourier transform is a complex quantity, with
information present in both magnitude and phase spectra. It is known from linear
system theory, that non minimum-phase signals have different information in
magnitude and phase spectra \cite{oppenheim}. Several studies \cite{mgd_complement}
have shown the complementarity of magnitude and phase, and how combining feature
vectors derived from each of them improves performance in various tasks. In this
paper, we study the effectiveness of feature-switching for speaker verification
using feature representations from magnitude-based and phase-based features. We
perform feature-switching using the standard Mel-frequency cepstra (MFCC)
\cite{mfcc}, which is derived from short-term magnitude, and the modified group delay feature
(MODGDF) \cite{hegdeModgdf}, which is derived from short-term phase. For each speaker, the
better-suited of these two representations is determined beforehand. Then,
feature-switching is applied for speaker verification by verifying some speakers
using MFCC features, and others using MODGDF features.

We study feature-switching for speaker verification in the context of the
classical GMM-UBM system \cite{reynoldsAdaptedGMM}, and also the more
sophisticated i-vector based representation \cite{dehak_ivector}. In both cases,
our studies show that feature-switching improves verification accuracy, when compared to
conventional baseline systems, as well as fusion systems. Experiments are performed on the
NIST 2010 speaker recognition evaluation (SRE) \cite{nist2010SRE} data.


\section{Separability analysis in different feature spaces}
\label{sec:separability}
The underlying hypothesis for feature-switching is that speakers are separated
differently in different feature spaces. To study this in more detail, we
perform separability studies in MFCC space and MODGDF space.

In the classical GMM-UBM framework \cite{reynoldsAdaptedGMM}, a speaker is
represented by a Gaussian mixture model (GMM). Given feature vectors extracted
from a speech utterance, the likelihood ratio of the speaker GMM and the
universal background model (UBM) is computed. Better separation between the GMM
and the UBM implies improved accuracy in verification.

\begin{figure}[h]
\centering 
\begin{minipage}[c]{0.5\textwidth}
\centering 
%	\begin{figure}
    \includegraphics[scale=0.30]{figures/tdcap_mfcc.eps}
	\caption*{(a)}
%	\label{fig:GmmMgdOpt}
%	\end{figure}
\end{minipage}%
\begin{minipage}[c]{0.35\textwidth}
\centering  
%	\begin{figure}
    \includegraphics[scale=0.30]{figures/tdcap_mgd.eps}
	\caption*{(b)}
%	\label{fig:GmmMfcOpt}
%	\end{figure}
\end{minipage}
\caption{Sub-figures (a) and (b) show the same speaker and background model
centroids in MFCC and MODGDF spaces. This speaker and the UBM are better
separable in MODGDF space.}
\label{fig:ubm_sep1}
\end{figure}

\begin{figure}[h]
\centering 
\begin{minipage}[c]{0.45\textwidth}
\centering 
%	\begin{figure}
    \includegraphics[scale=0.30]{figures/tecer_mfcc.eps}
	\caption*{(a)}
%	\label{fig:GmmMgdOpt}
%	\end{figure}
\end{minipage}%
\begin{minipage}[c]{0.45\textwidth}
\centering  
%	\begin{figure}
    \includegraphics[scale=0.30]{figures/tecer_mgd.eps}
	\caption*{(b)}
%	\label{fig:GmmMfcOpt}
%	\end{figure}
\end{minipage}
\caption{Sub-figures (a) and (b) show the same speaker and background model
centroids in MFCC and MODGDF spaces. This speaker and the UBM are better
separable in MFCC space.}
\label{fig:ubm_sep2}
\end{figure}

Figures \ref{fig:ubm_sep1} and \ref{fig:ubm_sep2} illustrate the
separability obtained in MFCC and MODGDF feature spaces for two different
speakers. The mean vectors of a 32-mixture GMM and UBM are plotted in
two-dimensional space. In these figures, the 39-dimensional MFCC and MODGDF
feature vectors are reduced to two dimensions using the Sammon mapping technique \cite{sammon}. Sammon mapping represents N-
dimensional vectors\ from N-space to a lower-dimensional space such
that the inherent data structure is preserved.  It can be seen that in Figure \ref{fig:ubm_sep1}(b), there is
better separation between the GMM and the UBM in the MODGDF space, when compared
to the MFCC space. Thus, it is likely that this speaker is better discriminated
against the UBM in the MODGDF space. Similarly, for a different speaker, 
Figure \ref{fig:ubm_sep2}(a) shows better separation in the MFCC space. Thus,
for this speaker, performing verification in the MFCC space gives better
discrimination between the UBM and the GMM. 

\begin{figure}[h!tb]
\centering \hspace{-5cm}
\begin{minipage}{0.65\textwidth}
\centering 
\includegraphics[scale=0.5]{figures/spkr1_mfcc.eps}
\caption*{(a)}
\label{fig:subfig3}
\end{minipage}%
\begin{minipage}{0.25\textwidth}
\centering \hspace{10cm}
\includegraphics[scale=0.5]{figures/spkr3_mgd.eps}
\caption*{(b)}
\label{fig:subfig4}
\end{minipage}
\caption{Sub-figures (a) and (b) show the i-vectors of target and impostor
trials in MFCC and MODGDF spaces. This target and impostor i-vectors are better
separable in MFCC space for the speaker in (a) and in MODGDF space for the
speaker  in (b).}
\label{fig:ivec_separation}
\end{figure}

Similar analysis is performed in i-vector space by considering the i-vectors of
target and non-target utterances of a speaker. The better separation of target
and non-target i-vectors in optimal feature domain can be readily seen in 
Figure \ref{fig:ivec_separation}. For a given speaker, target trials are those
spoken by the speaker himelf or herself, and are also called true-speaker
trials. Non-target trials are spoken by other speakers, and are also called
imposter trials. In this figure, 38-dimensional dimension i-vectors are
reduced to two dimensions using Sammon mapping.


\section{Optimal feature selection and feature-switching}
\label{sec:optFeat}

Speaker verification is a two-class problem. A verification trial consists of a
test utterance from an unknown speaker, and a speaker claim. Feature-switching
can be naturally applied to the verification scenario by performing
verification in the well-suited feature space of the claimed speaker. This
well-suited feature representation is henceforth termed as the \emph{optimal
feature}. The overall architecture of the feature-switching system is shown in the
Figure \ref{fig:systemArch}. The optimal feature is determined for every speaker
during enrolment, and stored into a lookup-table. During testing, the optimal
feature of the claimed speaker is looked-up, and verification is performed in
the optimal feature space.

\begin{figure}[th]
\centering
\includegraphics[scale=0.25]{figures/FS_Architect.eps}
\caption{System architecture with training and testing phase for feature-switching.}
\label{fig:systemArch}
\end{figure}



\subsection{Determining the optimal feature for the GMM-UBM framework}
\label{subsec:ubm_optFeat}

For the GMM-UBM framework, the method of determining the optimal feature for a
particular speaker, given a set of candidate feature representations, is
described in \cite{padmanInterspeech2010}. The optimal feature is determined by
evaluating the representation ability and discrimination ability
of each candidate feature representation. Given an enrolment utterance, the
mutual information between extracted feature vectors and the complex Fourier
transform (CFT) is used as an estimate of information captured by the feature
vectors. Thus, the representation ability of the feature representation is given
as 
\begin{equation}
\textrm{mi}(\textrm{CFT},X),
\end{equation}
where $\textrm{mi}$ represents the mutual information, CFT is the complex
Fourier transform, and $X$ is a set of feature vectors, which are computed from
the utterance.


The discrimination ability is determined by estimating the Kullback-Leibler divergence
(KL-divergence) between the UBM ($\lambda_{ubm}$) and the speaker GMM adapted 
($\lambda_{spk}$) from it. Because of the one-to-one
correspondence between the mixture components of the background model and the speaker model, 
the KL-divergence can be expressed in closed-form. For two uni-modal Gaussian distributions
$\hat{f}$ and $\hat{g}$, the KL-divergence has the closed form expression
\begin{equation}
\begin{split}
\textrm{kld}(\hat{f},\hat{g}) = \frac{1}{2}\left[ \log \frac{|\Sigma_g|}{|\Sigma_f|} +
	\textrm{Tr}|\Sigma^{-1}_g\Sigma_f| - d + \right. \\ 
\left. (\mu_f-\mu_g)^T\Sigma_g^{-1}(\mu_f-\mu_g) \frac{}{} \right], 
\end{split}
\label{eq:kldGaussians}
\end{equation}

where $\hat{f} = \mathcal{N}(\mu_f,\Sigma_f)$ and $\hat{g} = \mathcal{N}(\mu_g,\Sigma_g)$.

For a speaker models $\lambda_{spk}$, whose means are adapted from the UBM model
$\lambda_{ubm}$ (the covariances and mixture weights are same as that of the UBM), 
the KL-divergence reduces to 
\begin{equation}
\textrm{kld}(\lambda_{\textrm{spk}},\lambda_{\textrm{UBM}}) = 
	\Sigma_i\, \pi_i\, \textrm{kld}(f_i,g_i),
\label{eq:gmmAdaptedKLD}
\end{equation}

%where $\lambda_{\textrm{spk}} = \Sigma_i \, \pi_i \, \mathcal{N}(\mu_i^{\textrm{spk}},\Sigma)$ 

where $\lambda_{\textrm{spk}} = \Sigma_i \, \pi_i \, f_i$, and
$\lambda_{\textrm{UBM}} = \Sigma_i \, \pi_i \, g_i$, and
$f = \mathcal{N}(\mu_{\textrm{spk}},\Sigma)$, and
$g = \mathcal{N}(\mu_{\textrm{UBM}},\Sigma)$ and
$\pi$ are the mixture weights.


The optimal feature for a particular speaker is determined from the combined
representative and discriminative measures of each of the $P$ candidate
features. For the $p$th feature representation, we determine

\begin{eqnarray*}
&& \theta_p = \textrm{mi}(\textrm{CFT},X_{p}), \\
&& \gamma_p =
\textrm{kld}(\lambda_{\textrm{spk},p},\lambda_{\textrm{UBM},p}), \\
\end{eqnarray*} 
where $X_p$ are feature vectors, the speaker model $\lambda_{\textrm{spk}}$ and 
UBM $\lambda_{\textrm{UBM}}$ are in the $p$th feature space, and $p$ ranges from 1 to $P$.


%\in
%\{\textrm{MFCC},\textrm{LPCC},\textrm{MODGDF},\textrm{fSlope}\}$,  $\mathcal{X}$
%represents the complex Fourier spectrum, $\mathcal{Y}_i$ represents the $i$ th feature
%representation, $\lambda_{\textrm{spk},i}$ is the speaker model and $\lambda_{\textrm{UBM},i}$
%is the background model,
%using the $i$ th feature representation.


A linear combination of these two measures is determined 

\begin{equation}
\phi_p = \alpha \theta_p  + (1-\alpha) \gamma_p,
\label{eq:phiFunc}
\end{equation}

where $\alpha$ is a weighting parameter determined experimentally. The optimal
feature $\hat{p}$ for a given speaker is determined as 

\begin{equation}
\hat{p} = \arg\max_p \{\phi_p\}.
\label{eq:ubm_optFeat}
\end{equation}

\subsection{Determining the optimal feature in the i-vector framework}
\label{subsec:ivec_optFeat}

The i-vector representation \cite{dehak_ivector} is a a fixed-length
representation of speech utterances, which usually have a variable number of
traditional feature vectors.  Given an $FM \times 1$ super-vector of means $\mu$
derived from a UBM, a speaker and recording specific super-vector $s$ is assumed to of
the form

\begin{equation}
s = \mu + T w.
\end{equation}

Here, acoustic feature vector is $F$-dimensional, the UBM has $M$ components,
$T$ is an $FM \times D$ low-rank matrix, and $w$ is a $D \times 1$ latent
vector, with a standard normal distribution $w \sim \mathcal{N}(0,I)$. The
i-vector is estimated as the mean of the posterior distribution of $w$, given
the utterance. Procedures to estimate the hyper-parameters $\mu$ and $T$, and 
estimate i-vectors from an utterance, can be found in \cite{dehak_ivector}.

The i-vector representing an utterance encodes information about the message,
the speaker, and the channel. To compensate for unwanted channel effects,
several preprocessing steps like length normalization \cite{garcia_lengthNorm},
and within-class covariance normalization (WCCN) \cite{wccn} is performed. A
popular method to measure similarity between two i-vectors is by computing the
cosine distance \cite{dehak_ivector}.

For a given utterance, i-vectors can be estimated from different acoustic
feature vectors and their associated hyper-parameters. Hence, the
better-suited i-vector representation for a particular speaker can be estimated
from amongst i-vectors extracted from different acoustic features. One way of
doing this is by determining the i-vector representation which has the maximum
distance between the given speaker and the other enrolment speakers. If there
are $N$ speakers, the optimal i-vector representation $\Hat{p}$ 
for the $i$th speaker can be determined as

\begin{equation}
\Hat{p} = \arg\max_p \{s_p\},
\label{eq:opt_ivec}
\end{equation}

where 

\begin{equation}
s_p = \frac{\displaystyle \sum_{j=1, \; i \neq j}^N d(w_{p,i},w_{p,j})}{N}.
\label{eq:sp}
\end{equation}

Here, $w_{p,j}$ represents the enrolment i-vector for the $j$th speaker
extracted using the $p$th feature representation. $d$ is a distance measure (for
example, cosine distance) between i-vectors. For the $i$th speaker, the average
distance with the other enrolment speakers is used to determine the optimal
i-vector representation. 

\section{Features from magnitude and phase spectra}
\label{sec:featExt}

The underlying assumption in feature-switching is that information in different
feature representations can be utilised dynamically. Earlier studies \cite{complement1},
\cite{complement2}, \cite{mgd_complement} have demonstrated complementary information in
magnitude and phase spectra. Mel frequency cepstra (MFCC) are derived from the magnitude
spectrum. A popular method for utilising information from the phase spectrum is
via group delay functions \cite{group_delay}. The modified group delay feature (MODGDF) 
\cite{modgd_feat}, which is derived from the modified group delay function
\cite{modgd_func}, have been explored as complementary features to MFCCs. The procedure for
extracting MODGDF features are briefly described below. More details regarding the theory
of MODGF can be found in \cite{modgd_func} and \cite{modgd_feat}. The algorithm for extracting the MODGDF feature is given below as in \cite{hegdeModgdf}.

\begin{algorithm}
\caption{Algorithm 1: MODGDF Extraction}
\label{alg:mgdExtraction}
\textbf{Input:} A frame of speech signal $x(n)$  \\
\textbf {Output:} MODGDF features c(n). 
\begin{algorithmic}[1]
%\Procedure{}{} \\
\State Compute the DFT $X(k)$ of the speech frame $x(n)$. 
\State Compute the DFT $\hat{X(k)}$ of the signal $nx(n)$. 
\State Compute the cepstrally smoothed spectra of $X(k)$ and denote it as $S(k)$. Length of window in cepstral domain is controlled by the lifter parameter $\omega$ 
\State MODGD function is computed as:
		\begin{equation*}
			\tau_{m}(k)=\left( \frac{\tau (k)}{\left| \tau (k) \right|} \right) \left( \left| \tau(k) \right| \right)^{\alpha}
	\end{equation*} where
	\begin{equation*}
		 \tau(k)=\frac{X_R(k)\hat{X}_R(k)+X_I(k)\hat{X}_I(k)}{\left| S(k)\right|^{2\gamma}}
	\end{equation*} $\alpha$ and $\gamma$ are the parameters used to control the dynamic range of the MODGD function.
\State By taking the DCT of the MODGD, MODGDF features are computed as 
\begin{equation*}
	c(n)=\sum_{k=0}^{N_f-1}\tau_m(k)cos(n(2k+1)\pi/N_f), \;\; 0\leq n < N_c
	\end{equation*}	
	where $N_f$	  is the DFT size and $N_c$ is the number of cepstral coefficients.

%\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Experimental evaluation}
\label{sec:expts}
This section details the experimental evaluation of speaker verification in the
feature-switching framework. We give details about the datasets used, the
development of the feature-switching system, and comparisons with baseline and
fusion systems.

\subsection{Dataset description}
\label{sec:dB}
Speaker verification experiments are performed on a subset of
the NIST 2010 SRE dataset. Telephone and microphone utterances under varying vocal effort, as detailed in \cite{nist2010SRE}
are used for enrolment and evaluation. These are summarised in Table \ref{tab:datasetConditions}. Hyper-parameters for the speaker recognition systems are developed using data from SRE99, SRE03, SRE04, SRE05, SRE06, SRE08, and SRE08-extended data.

\begin{table}[h!tb]
\centering
\caption{Test Conditions for Evaluation Data}
\begin{tabular}{|c|c|c|c|}
\hline
Condition & Channel & Training Vocal Effort & Testing Vocal Effort \\ 
\hline \hline
C5 & Telephone & Normal & Normal \\ \hline
C6 & Telephone & Normal & High \\ \hline
C7 & Microphone & Normal & High \\ \hline
C8 & Telephone & Normal & Low \\ \hline
C9 & Microphone & Normal & Low \\ \hline
\end{tabular}
\label{tab:datasetConditions}
\end{table}



\subsection{Baseline verification systems}
\label{subsec:baseline}

Feature-switching is performed on two speaker verification frameworks: the GMM-UBM system \cite{reynoldsAdaptedGMM}, and
the i-vector system \cite{dehak_ivector}. The evaluation metric
used is the equal error rate (EER), and is evaluated separately
for male and female genders.

\textbf{Voice activity detection (VAD)}: VAD is a crucial
 component in all speech processing systems. In our systems,
 speech frames of 25 ms size, with a frame shift of 10 ms are 
 utilised. Since the utterances are fairly clean, a simple VAD 
 using threshold on average short-term energy is utilised. This
 typically discards about 20-25\% of the input frames.

\textbf{GMM-UBM system:} GMM-UBM systems are developed separately for MFCC and MODGDF feature representations. 
38-dimensional feature vectors are extracted in each feature 
domain. Gender-dependent 1024-mixture UBMs are built 
from development data.  Speaker-dependent GMM models are generated for the enrolment data by adapting the means of top
10 maximum contributing mixture components of the UBM. For each
test utterance, similarity scores are computed as the ratio of
the log-likelihood of the extracted features with the UBM and
the speaker model.

The baseline systems are denoted as follows.
\begin{enumerate}
\item UBM-MFC-male : Male speaker verification system with MFCC feature
\item UBM-MFC-female : Female speaker verification system with MFCC feature
\item UBM-MGD-male : Male speaker verification system with MODGD feature
\item UBM-MGD-female : Female speaker verification system with MODGD feature
\end{enumerate}

\textbf{i-vector system:} 
38-dimensional feature vectors are extracted and first and
 second order super-vector statistics are computed using a
 1024-mixture UBM. A total variability matrix of size 38912
 $\times$ 600 is randomly initialized and estimated using
 development data, as detailed in \cite{dehak_ivector, kenny_JFA}. 
500-dimensional i-vectors are estimated for each enrolment
utterance and test utterance. Preprocessing steps to reduce
channel variability including i-vector length normalization
\cite{garciaRomero}, linear discriminant analysis (LDA) and
within-class covariance normalization (WCCN) are applied to the
i-vectors.

%What is the data used to estimate the LDA and WCCN matrices?
LDA followed by WCCN is used to achieve better performance as in \cite{dehak_ivector}. All possible classes from development
data is subjected to LDA and WCCN and a projection matrix is obtained. Each class is made up of all the recording of a single speaker. The i-vectors are then subjected to this projection matrix to maximize the discrimination between the speakers. Cosine similarity between enrolment and test 
i-vectors is utilised to determine the similarity score between
them.

The four different baseline systems developed in this framework
are referred as ivec-MFC-male, ivec-MFC-female, ivec-MGD-male
and ivec-MGD-female.

In both the GMM-UBM and the i-vector frameworks, similarity
scores calculated between the test and enrolment utterances 
are subjected to T-normalization \cite{tnorm}. True and impostor
models for every speaker is given along with the database. Each 
test utterance is scored against those fixed set of true and imposter 
speaker models. From this set of scores, the mean and standard
deviation are computed and T-Normalization is performed. The 
EERs of these baseline systems are listed in the Table \ref{tab:eer}.
%%% \textbf {What is the devel data for score norm?}


\textbf{Feature-level fusion:} The traditional way of combining
information from multiple feature representations is to combine
them either at the feature-level or at the score-level \cite{fusion}. In our experiments, this procedure is applied to
both the GMM-UBM system, and the i-vector system. Feature-level fusion also known as early fusion, is achieved by fusing the
38-dimensional MFCC and MODGDF feature vectors used in baseline
systems to get a 76-dimensional feature vector. Using these
feature vectors, gender-dependent speaker verification systems
 are built. These systems are indicated as EF-UBM-male, 
 EF-UBM-female, EF-ivec-male, and EF-ivec-female. The EERs of
 these systems are shown in Table  \ref{tab:eer}.

\textbf{Score-level fusion:}  Score-level fusion is achieved by
fusing the scores of individual feature-based baseline systems
\cite{fusion}. The fusion scores are a linear combination of
the MFCC and MODGDF scores. A line search is performed to find
the optimal weighing parameter. These systems are denoted as
SF-GMM-male, SF-GMM-female, SF-ivec-male and SF-ivec-female.
The performance of the fusion systems are given in Table
\ref{tab:eer}. 

	
\subsection{Feature-switching}
\label{subsec:featSwitch}

In the proposed feature-switching framework, different speaker
claims are verified using different feature representations. 
Experimental evaluation of feature-switching is done in both
GMM-UBM and i-vector frameworks. The details of these systems
are given below.

\begin{figure}[h]
\includegraphics[scale=0.35]{figures/FeatureSwithcing.eps}
\caption{Testing phase of feature-switching system}
\label{fig:systemArch2}
\end{figure}


\textbf{GMM-UBM feature-switching system:}
The baseline systems (MFCC and MODGDF) described in section \ref{subsec:baseline} form the
constituent systems for feature-switching. This is shown in Figure \ref{fig:systemArch2}. For each enrolment
speaker, the optimal feature is determined from the enrolment utterance, as described in section
\ref{subsec:ubm_optFeat}. Here, the number of candidate features, $P$, is two,
with $p=1$ meaning MFCC features and $p=2$ meaning MODGDF features.

The weighting parameter $\alpha$ is used as a trade-off between mutual information and
KL-divergence for determining the optimal feature of a given speaker (equation
\ref{eq:phiFunc}). Different speakers can have different $\alpha$ values. Since
there is no theoretical insight to determining the correct weighting feature,
the following procedure is adopted for each of the $N$ enrolment speakers.
For a given speaker, the value of $\phi_p$ is determined accross various values
of $\alpha$ as, 
\begin{equation}
\phi_p = \max \; \alpha \theta_p + (1-\alpha) \gamma_p
\end{equation}
where the values of $\alpha$ are varied from $0$ to $1$ in steps of $0.1$. Once
$\phi_p$ is determined for $p=1$ and $p=2$, the optimal feature is computed as in equation
\ref{eq:ubm_optFeat}.

Out of 1402 male  and 1758 female enrolment speakers in the SRE 2010
dataset, 734 male  and 641 female speakers chose MODGDF and 
remaining chose MFCC as their optimal feature. Approximately, 890
male utterances and 1100 female utterances were used across the five
different test conditions listed in Section \ref{sec:dB}. The two feature-switching systems are developed in this framework are denoted as 
FS-UBM-male, and FS-UBM-female. The distribution of speakers in both feature domain for these feature switching systems are listed in the Table \ref{tab:ubm-spkrCount}.


\textbf{i-vector feature-switching system:}
As in the case of the GMM-UBM system, the MFCC and MODGDF i-vector systems
described in section \ref{subsec:baseline} are the constituent systems for the
feature-switching system. For each speaker, the optimal feature representation
is computed as described in equation \ref{eq:opt_ivec}. For the SRE 10 dataset,
the optimal features are summarised as given below.

Out of 1402 male and 1758 female enrolment data, 26 and 1673
trials chose MODGDF as their optimal feature respectively.
The same test set used for feature-switching in UBM-GMM framework 
is used here. The two feature-switching systems are developed in this
framework are denoted as FS-UBM-male, and FS-UBM-female. The distribution of speakers in both feature domain for these feature switching systems are listed in the Table \ref{tab:ivec-spkrCount}.
The resulting EERs for these systems are also described in Table \ref{tab:eer}.

\section{Result Analysis}
\label{subsec:resAnalysis}

\begin{table}[h]
	\centering
	\caption{EERs in \% for baseline systems, score fusion (SF) systems and
	feature switching (FS) systems in UBM-GMM and i-vector frameworks}
	\begin{tabular}{|c|c|c|c|c|c|} \hline
 {\bf System} & {\bf C5 } &  {\bf C6} & {\bf C7} & {\bf C8}  & {\bf C9  }\\ \hline \hline
\multicolumn{6}{|c|}{\bf Baseline Systems} \\ \hline
UBM-MFC-Male & 17.27 & 18.09 & 18.06 & 11.82 & 4.55 \\ \hline

UBM-MGD-Male & 19.54 & 19.89 & 11.65 & 13.99 & 5.19 \\ \hline

{UBM-MFC-Female} & 18.07 & 22.19 & 27.74 & 11.01 & 4.76 \\ \hline

{UBM-MGD-Female} & 22.64 & 22.15 & 18.07 & 15.14 & 7.14 \\ \hline

{ivec-MFC-Male} & 5.10 & 6.20 & 7.44 & 2.17 & 3.13 \\ \hline

{ivec-MGD-Male} &  6.26 & 8.02 & 7.06 & 3.02 & 3.31  \\ \hline

{ivec-MFC-Female} & 6.25 & 9.32 & 16.55 & 4.60 & 3.65 \\ \hline

{ivec-MGD-Female} & 7.02 & 9.89 & {\bf 11.64} & 3.98 & 3.73 \\ \hline 

\multicolumn{6}{|c|}{\bf Early Fusion Systems} \\ \hline

{EF-UBM-Male} & 17.97 & 20.22 & 12.84 & 15.94 & 6.14\\ \hline

{EF-UBM-Female} & 17.56 & 20.67  & 23.1  & 13.11 & 5.42  \\ \hline

{EF-ivec-Male} & 18.61 & 18.15 & 12.7 & 11.1 & 6.41 \\ \hline

{EF-ivec-Female} & 7.91 & 11.8 & 14.83 & 6.13 & 4.64 \\ \hline 

\multicolumn{6}{|c|}{\bf Score Fusion Systems} \\ \hline

SF-UBM-Male & 16.71 & 16.38 & 11.04 & 9.79 & 4.43 \\ 
%(weights:MGD+MFC) & (0.4+0.6) & (0.5+0.5) & (0.8+0.2) & (0.1+0.9) & (0.3+0.7) \\ 
\hline

SF-UBM-Female & 17.80 & 20.27 & 17.26 & 10.40 & 3.24 \\ 
%(weights:MGD+MFC) & (0.3+0.7) & (0.5+0.5) & (0.9+0.1) & (0.2+0.8) & (0.4+0.6) \\ 
\hline

SF-ivec-Male & 4.48 & 5.39 & 6.74 & 1.99 & 3.09 \\ 
%(weights:MGD+MFC) & (0.3+0.7) & (0.3+0.7) & (0.7+0.3) & (0.2+0.8) & (0.3+0.7) \\ 
\hline

SF-ivec-Female & 5.52 & 7.53 & 13.33 & 3.83 & 3.44 \\ 
%(weights:MGD+MFC) & (0.2+0.8) & (0.5+0.5) & (0.9+0.1) & (0.3+0.7) & (0.4+0.6) \\
 \hline

\multicolumn{6}{|c|}{\bf Feature Switching Systems} \\ \hline

{FS-UBM-Male} & {10.48} & {12.32} & {9.06} & {9.4} & {3.21} \\  \hline

{FS-UBM-Female} & {15.12 } & {18.39} & {14.14} & {9.89} & {4.27} \\ \hline

 {FS-ivec-Male} & {\bf 3.56} & {\bf 4.86} & {\bf 5.57} & {\bf 1.36} & {\bf 2.48} \\ \hline

{FS-ivec-Female} & {\bf 5.62} & {\bf 8.58} & 11.86 & {\bf 3.61} & {\bf 3.52} \\ \hline

	\end{tabular}
	\label{tab:eer}
	\end{table}


The various speaker verification systems described in Section \ref{sec:expts} include four baseline systems (UBM-MFC, UBM-MGD, ivec-MFC, ivec-MGD), two score fusion systems (give names) and
two proposed feature-switching systems. Each of these have corresponding systems
for male trials and female trials. The performance metric is the equal error
rate (EER.) These are tabulated in table \ref{tab:eer}.

%In all cases, give the relative improvement.
As expected, the score fusion system performs better than the individual
baseline systems. In test conditions C6 and C8 for SF-UBM-Male system, 
there is approximately 1.8\% of improvement in EER compared to the baseline systems. Similarly for test conditions C5, C7, and C9, for the same system, the improvement in performance is about 0.4\% of improvement is observed in same system. Similarly for 
the test cases C5 and C7 of SF-UBM-Female system, performance is improved around 0.5\%.
For the same system, nearly 1.5\% of performance improved is seen for test cases C6, C8 and
C9.

$******************************************* $ \\
Why is early fusion poor? Justify. \\
$*******************************************$ \\

It is evident from the results that performance of the score-fusion system is better than the early fusion systems and baseline systems. But the feature switching system outperforms the score-fusion systems in both the frameworks in all test cases except for case C7 in female database.

The comparison of best baseline system and feature switching system, along with
the number of speakers in the optimal feature space in listed in the Table
\ref{tab:ubm-spkrCount} and \ref{tab:ivec-spkrCount}. For male database in
i-vector framework, only 1.8\% of training data chose MODGDF as their optimal
feature. Thus fewer test utterances chose MODGDF as optimal feature (last column
of the Table \ref{tab:ubm-spkrCount}). 
%Give table here.
\begin{table}[h!tb]
\centering
\caption{The distribution of speakers in the feature spaces using feature switching in UBM-GMM framework. (EERs of baseline system and feature switching systems are compared and lesser EER in given in bold font)}
\begin{tabular}{cc|c|c|c|}
\cline{3-5}
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{3}{c|}{UBM-GMM Framework} \\ \hline
\multicolumn{1}{|c|}{Gender} & Condition & \begin{tabular}[c]{@{}c@{}}Best Baseline \\ EER\end{tabular} & \begin{tabular}[c]{@{}c@{}}Feature \\ Switching\\ EER\end{tabular} & \begin{tabular}[c]{@{}c@{}}Speaker Count\\ (MGD/MFCC)\end{tabular} \\ \hline
\multicolumn{1}{|c|}{\multirow{5}{*}{Male}} & C5 & 17.27 (MFC) & {\bf 10.48} & 168/187 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C6 & 18.09 (MFC) & {\bf 12.32} & 113/34 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C7 & 11.65 (MGD) & {\bf 9.06} & 96/53 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C8 & 11.82 (MFC) & {\bf 9.4} & 64/52 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C9 & 4.55 (MFC) & {\bf 3.21} & 67/48 \\ \hline
\multicolumn{1}{|c|}{\multirow{5}{*}{Female}} & C5 & 18.07 (MFC) & {\bf 15.12} & 76/281 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C6 & 22.15 (MGD) & {\bf 18.39} & 62/123 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C7 & 18.07 (MGD) & {\bf 14.14} & 33/152 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C8 & 11.01 (MFC) & {\bf 9.89} & 78/106 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C9 & 4.76 (MFC) & {\bf 4.27} & 75/106 \\ \hline
\end{tabular}
\label{tab:ubm-spkrCount}
\end{table}

%Give table here.
\begin{table}[h!tb]
\centering
\caption{The distribution of speakers in the feature spaces using feature switching in UBM-GMM framework. (EERs of baseline system and feature switching systems are compared and lesser EER in given in bold font)}
\begin{tabular}{cc|c|c|c|}
\cline{3-5}
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{3}{c|}{i-vector Framework} \\ \hline
\multicolumn{1}{|c|}{Gender} & Condition & \begin{tabular}[c]{@{}c@{}}Best Baseline \\ EER\end{tabular} & \begin{tabular}[c]{@{}c@{}}Feature\\  Switching\\ EER\end{tabular} & \begin{tabular}[c]{@{}c@{}}Speaker Count\\ (MGD/MFCC)\end{tabular} \\ \hline
\multicolumn{1}{|c|}{\multirow{5}{*}{Male}} & C5 & 5.10 (MFC) & {\bf 3.56} & 8/352 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C6 & 6.20 (MFC) & {\bf 4.86} & 6/146 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C7 & 7.06 (MGD) & {\bf 5.57} & 7/147 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C8 & 2.17 (MFC) & {\bf 1.36} & 8/116 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C9 & 3.13 (MFC) & {\bf 2.48} & 4/115 \\ \hline
\multicolumn{1}{|c|}{\multirow{5}{*}{Female}} & C5 & 6.25 (MFC) & {\bf 5.62} & 193/164 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C6 & 9.32 (MFC) & {\bf 8.58} & 102/83 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C7 & {\bf 11.64 (MGD)} & 11.86 & 176/9 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C8 & 3.98 (MGD) & {\bf 3.61} & 86/98 \\ \cline{2-5} 
\multicolumn{1}{|c|}{} & C9 & 3.65 (MFC) & {\bf 3.52} & 170/11 \\ \hline
\end{tabular}
\label{tab:ivec-spkrCount}
\end{table}


\vspace{0.25cm}
MODGDF is generally preferred over MFCC feature for male and MFCC is preferred for female over MODGDF in UBM-GMM framework. The complete reverse scenario is observed in i-vector framework, where MFCC is preferred for most of the test cases in male and MODGDF is preferred for female. On comparing the i-vector and UBM-GMM framework, out of 1402 trials 
in the male enrolment data, 730 trials chose different optimal feature. Likewise, out of 1758 trials in female enrolment data, 1136 trials adopted different optimal features.


The considerable reduction in EERs of feature-switching systems in all cases except for C7 in FS-ivec-female system, demonstrates feature-switching systems are efficient than the score-fusion and baseline systems. 
\\$**********************$ \\
The exception may be due to reverberation in high vocal effort testing \cite{vocalEffort} {\bf (I am not clear with the justification here Sir...!)}. \\ $**********************$ \\
Overall performance of i-vector systems are better than UBM-GMM systems.  

\vspace{0.25cm}
\section{Conclusion}
\label{sec:conclude}
\vspace{0.25cm}
\section{Acknowledgement}
\label{sec:ack}


\clearpage 

\bibliographystyle{IEEEtranS}
\bibliography{refs}


\end{document}
